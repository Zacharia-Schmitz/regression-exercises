{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walker Texas Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises I - Repo Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a new repository named regression-exercises in your GitHub; all of your Regression work will be housed here.\n",
    "- Clone this repository within your local codeup-data-science directory.\n",
    "- Create a .gitignore and make sure your list of 'files to ignore' includes your env.py file.\n",
    "- Ceate a README.md file that outlines the contents and purpose of your repository.\n",
    "- Add, commit, and push these two files.\n",
    "- Now you can add your env.py file to this repository to access the Codeup database server.\n",
    "- For these exercises, you will create wrangle.ipynb and wrangle.py files to hold necessary functions.\n",
    "- As always, add, commit, and push your work often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise II - Acquire and Prep (Wrangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's set up an example scenario as perspective for our regression exercises using the Zillow dataset.\n",
    "\n",
    "- As a Codeup data science graduate, you want to show off your skills to the Zillow data science team in hopes of getting an interview for a position you saw pop up on LinkedIn. You thought it might look impressive to build an end-to-end project in which you use some of their Kaggle data to predict property values using some of their available features; who knows, you might even do some feature engineering to blow them away. Your goal is to predict the values of single unit properties using the obervations from 2017.\n",
    "\n",
    "- In these exercises, you will complete the first step toward the above goal: acquire and prepare the necessary Zillow data from the zillow database in the Codeup database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zillow(user=user, password=password, host=host):\n",
    "    \"\"\"\n",
    "    This function wrangles data from a cached CSV or SQL database, drops unneeded columns and null\n",
    "    values, and returns a cleaned dataframe of Zillow property data.\n",
    "\n",
    "    :param user: The username for accessing the MySQL database\n",
    "    :param password: Please make sure to keep your password secure and not share it with anyone\n",
    "    :param host: The host parameter is the address of the server where the MySQL database is hosted\n",
    "    :return: a pandas DataFrame containing cleaned and wrangled data from the Zillow database for single\n",
    "    family residential properties. The DataFrame includes columns for bedroom count, bathroom count,\n",
    "    calculated finished square footage, tax value in dollars, year built, tax amount, and FIPS code. The\n",
    "    function drops unneeded columns and null values before returning the DataFrame.\n",
    "    \"\"\"\n",
    "    # name of cached csv\n",
    "    filename = \"zillow.csv\"\n",
    "    # if cached data exist\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    # wrangle from sql db if not cached\n",
    "    else:\n",
    "        # read sql query into df\n",
    "        # 261 is single family residential id\n",
    "        df = pd.read_sql(\n",
    "            \"\"\"select yearbuilt\n",
    "                                    , bedroomcnt\n",
    "                                    , bathroomcnt\n",
    "                                    , calculatedfinishedsquarefeet\n",
    "                                    , taxvaluedollarcnt\n",
    "                                    , taxamount\n",
    "                                    , fips \n",
    "                            from properties_2017\n",
    "                            where propertylandusetypeid = 261\"\"\",\n",
    "            f\"mysql+pymysql://{user}:{password}@{host}/zillow\",\n",
    "        )\n",
    "        # cache data locally\n",
    "        df.to_csv(filename, index=False)\n",
    "    # nulls account for less than 1% so dropping\n",
    "    df = df.dropna()\n",
    "    # rename columns\n",
    "    df = df.rename(\n",
    "        columns=(\n",
    "            {\n",
    "                \"yearbuilt\": \"year\",\n",
    "                \"bedroomcnt\": \"beds\",\n",
    "                \"bathroomcnt\": \"baths\",\n",
    "                \"calculatedfinishedsquarefeet\": \"area\",\n",
    "                \"taxvaluedollarcnt\": \"tax_value\",\n",
    "                \"taxamount\": \"prop_tax\",\n",
    "                \"fips\": \"county\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    # map county to fips\n",
    "    df.county = df.county.map({6037: \"LA\", 6059: \"Orange\", 6111: \"Ventura\"})\n",
    "    # make int\n",
    "    ints = [\"year\", \"beds\", \"area\", \"tax_value\"]\n",
    "    for i in ints:\n",
    "        df[i] = df[i].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Acquire bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, and fips from the zillow database for all 'Single Family Residential' properties.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import env as e\n",
    "import os\n",
    "\n",
    "\n",
    "def get_zillow():\n",
    "    # name of cached csv\n",
    "    filename = \"zillow.csv\"\n",
    "    # if cached data exist\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    # wrangle from sql db if not cached\n",
    "    else:\n",
    "        # read sql query into df\n",
    "        # 261 is single family residential id\n",
    "        df = pd.read_sql(\n",
    "            \"\"\"SELECT yearbuilt,\n",
    "                                   bedroomcnt,\n",
    "                                   bathroomcnt,\n",
    "                                   calculatedfinishedsquarefeet,\n",
    "                                   taxvaluedollarcnt,\n",
    "                                   taxamount,\n",
    "                                   fips\n",
    "                            FROM properties_2017\n",
    "                            WHERE propertylandusetypeid = 261\"\"\",\n",
    "            f\"mysql+pymysql://{e.user}:{e.password}@{e.host}/zillow\",\n",
    "        )\n",
    "        # cache data locally\n",
    "        df.to_csv(filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration Summary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_columns(df_telco):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe as input and returns\n",
    "    a dataframe with information about each column in the dataframe. For\n",
    "    each column, it returns the column name, the number of\n",
    "    unique values in the column, the unique values themselves,\n",
    "    the number of null values in the column, the proportion of null values,\n",
    "    and the data type of the column. The resulting dataframe is sorted by the\n",
    "    'Number of Unique Values' column in ascending order.\n",
    "\n",
    "    Args:\n",
    "    - df_telco: pandas dataframe\n",
    "\n",
    "    Returns:\n",
    "    - pandas dataframe\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # Loop through each column in the dataframe\n",
    "    for column in df_telco.columns:\n",
    "        # Append the column name, number of unique values, unique values, number of null values, proportion of null values, and data type to the data list\n",
    "        data.append(\n",
    "            [\n",
    "                column,\n",
    "                df_telco[column].nunique(),\n",
    "                df_telco[column].unique(),\n",
    "                df_telco[column].isna().sum(),\n",
    "                df_telco[column].isna().mean(),\n",
    "                df_telco[column].dtype,\n",
    "            ]\n",
    "        )\n",
    "    # Create a pandas dataframe from the data list, with column names 'Column Name', 'Number of Unique Values', 'Unique Values', 'Number of Null Values', 'Proportion of Null Values', and 'dtype'\n",
    "    # Sort the resulting dataframe by the 'Number of Unique Values' column in ascending order\n",
    "    return pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"Column Name\",\n",
    "            \"Number of Unique Values\",\n",
    "            \"Unique Values\",\n",
    "            \"Number of Null Values\",\n",
    "            \"Proportion of Null Values\",\n",
    "            \"dtype\",\n",
    "        ],\n",
    "    ).sort_values(by=\"Number of Unique Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using your acquired Zillow data, walk through the summarization and cleaning steps in your wrangle.ipynb file like we did above. You may handle the missing values however you feel is appropriate and meaningful; remember to document your process and decisions using markdown and code commenting where helpful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Number of Unique Values</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Number of Null Values</th>\n",
       "      <th>Proportion of Null Values</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>county</td>\n",
       "      <td>3</td>\n",
       "      <td>[6037.0, 6059.0, 6111.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beds</td>\n",
       "      <td>19</td>\n",
       "      <td>[0.0, 4.0, 3.0, 5.0, 2.0, 1.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baths</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.0, 2.0, 4.0, 1.0, 2.5, 3.5, 3.0, 5.5, 4.5, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>153</td>\n",
       "      <td>[nan, 2005.0, 2011.0, 1926.0, 1972.0, 1973.0, ...</td>\n",
       "      <td>9337</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sqfeet</td>\n",
       "      <td>10580</td>\n",
       "      <td>[nan, 3633.0, 1620.0, 2077.0, 1200.0, 171.0, 2...</td>\n",
       "      <td>8484</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tax_value</td>\n",
       "      <td>592269</td>\n",
       "      <td>[27516.0, 10.0, 2108.0, 296425.0, 124.0, 84777...</td>\n",
       "      <td>493</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prop_tax</td>\n",
       "      <td>918838</td>\n",
       "      <td>[nan, 174.21, 6941.39, 10244.94, 7924.68, 8034...</td>\n",
       "      <td>4442</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column Name  Number of Unique Values  \\\n",
       "6      county                        3   \n",
       "1        beds                       19   \n",
       "2       baths                       38   \n",
       "0        year                      153   \n",
       "3      sqfeet                    10580   \n",
       "4   tax_value                   592269   \n",
       "5    prop_tax                   918838   \n",
       "\n",
       "                                       Unique Values  Number of Null Values  \\\n",
       "6                           [6037.0, 6059.0, 6111.0]                      0   \n",
       "1  [0.0, 4.0, 3.0, 5.0, 2.0, 1.0, 6.0, 7.0, 8.0, ...                     11   \n",
       "2  [0.0, 2.0, 4.0, 1.0, 2.5, 3.5, 3.0, 5.5, 4.5, ...                     11   \n",
       "0  [nan, 2005.0, 2011.0, 1926.0, 1972.0, 1973.0, ...                   9337   \n",
       "3  [nan, 3633.0, 1620.0, 2077.0, 1200.0, 171.0, 2...                   8484   \n",
       "4  [27516.0, 10.0, 2108.0, 296425.0, 124.0, 84777...                    493   \n",
       "5  [nan, 174.21, 6941.39, 10244.94, 7924.68, 8034...                   4442   \n",
       "\n",
       "   Proportion of Null Values    dtype  \n",
       "6                   0.000000  float64  \n",
       "1                   0.000005  float64  \n",
       "2                   0.000005  float64  \n",
       "0                   0.004337  float64  \n",
       "3                   0.003941  float64  \n",
       "4                   0.000229  float64  \n",
       "5                   0.002063  float64  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = check_columns(df)\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010580329542567268"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[\"Proportion of Null Values\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "When Googling fips, 6037 = Los Angeles County\n",
    "                    6059 = Orange County\n",
    "                    6111 = Midland County\n",
    "\n",
    "- With this info, we'll rename 'fips' to 'county'\n",
    "\n",
    "- We'll rename 'bedroomcnt' to 'beds'\n",
    "               'bathroomcnt' to 'baths'\n",
    "               'yearbuilt' to 'year'\n",
    "               'calculatedfinishedsquarefeet' to 'sqfeet'\n",
    "               'taxvaluedollarcnt' to 'tax_value'\n",
    "               'taxamount' to 'prop_tax'\n",
    "\n",
    "- With all of the proportion of null values adding up to 0.0105 (1%), we will drop all NA in the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(\n",
    "    columns=(\n",
    "        {\n",
    "            \"yearbuilt\": \"year\",\n",
    "            \"bedroomcnt\": \"beds\",\n",
    "            \"bathroomcnt\": \"baths\",\n",
    "            \"calculatedfinishedsquarefeet\": \"sqfeet\",\n",
    "            \"taxvaluedollarcnt\": \"tax_value\",\n",
    "            \"taxamount\": \"prop_tax\",\n",
    "            \"fips\": \"county\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqfeet</th>\n",
       "      <th>tax_value</th>\n",
       "      <th>prop_tax</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>296425.0</td>\n",
       "      <td>6941.39</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>847770.0</td>\n",
       "      <td>10244.94</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1926.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>646760.0</td>\n",
       "      <td>7924.68</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>5328.0</td>\n",
       "      <td>91.60</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1973.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>255.17</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152856</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>422400.0</td>\n",
       "      <td>13877.56</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152858</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2262.0</td>\n",
       "      <td>960756.0</td>\n",
       "      <td>13494.52</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152859</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3127.0</td>\n",
       "      <td>536061.0</td>\n",
       "      <td>6244.16</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152861</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>424353.0</td>\n",
       "      <td>5302.70</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152862</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>554009.0</td>\n",
       "      <td>6761.20</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140235 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           year  beds  baths  sqfeet  tax_value  prop_tax  county\n",
       "4        2005.0   4.0    2.0  3633.0   296425.0   6941.39  6037.0\n",
       "6        2011.0   3.0    4.0  1620.0   847770.0  10244.94  6037.0\n",
       "7        1926.0   3.0    2.0  2077.0   646760.0   7924.68  6037.0\n",
       "11       1972.0   0.0    0.0  1200.0     5328.0     91.60  6037.0\n",
       "14       1973.0   0.0    0.0   171.0     6920.0    255.17  6037.0\n",
       "...         ...   ...    ...     ...        ...       ...     ...\n",
       "2152856  2015.0   4.0    4.0  4375.0   422400.0  13877.56  6037.0\n",
       "2152858  2015.0   4.0    3.0  2262.0   960756.0  13494.52  6059.0\n",
       "2152859  2014.0   4.0    4.5  3127.0   536061.0   6244.16  6059.0\n",
       "2152861  2015.0   3.0    2.5  1974.0   424353.0   5302.70  6059.0\n",
       "2152862  2014.0   4.0    4.0  2110.0   554009.0   6761.20  6037.0\n",
       "\n",
       "[2140235 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Store all of the necessary functions to automate your process from acquiring the data to returning a cleaned dataframe with no missing values in your wrangle.py file. Name your final function wrangle_zillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import env as e\n",
    "\n",
    "\n",
    "def wrangle_zillow():\n",
    "    \"\"\"\n",
    "    This function reads the Zillow data from a cached CSV file if it exists,\n",
    "    or from a SQL database if it doesn't exist. It then renames the columns\n",
    "    to more descriptive names.\n",
    "\n",
    "    Args:\n",
    "    - None\n",
    "\n",
    "    Returns:\n",
    "    - pandas dataframe\n",
    "    \"\"\"\n",
    "    # Name of cached CSV file\n",
    "    filename = \"zillow.csv\"\n",
    "    # If cached data exists, read from CSV file\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    # Otherwise, read from SQL database\n",
    "    else:\n",
    "        df = pd.read_sql(\n",
    "            \"\"\"SELECT yearbuilt,\n",
    "                                   bedroomcnt,\n",
    "                                   bathroomcnt,\n",
    "                                   calculatedfinishedsquarefeet,\n",
    "                                   taxvaluedollarcnt,\n",
    "                                   taxamount,\n",
    "                                   fips\n",
    "                            FROM properties_2017\n",
    "                            WHERE propertylandusetypeid = 261\"\"\",  # 261 is single family residential id\n",
    "            f\"mysql+pymysql://{e.user}:{e.password}@{e.host}/zillow\",\n",
    "        )\n",
    "        # Cache data locally\n",
    "        df.to_csv(filename, index=False)\n",
    "    # Rename columns\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"yearbuilt\": \"year\",\n",
    "            \"bedroomcnt\": \"beds\",\n",
    "            \"bathroomcnt\": \"baths\",\n",
    "            \"calculatedfinishedsquarefeet\": \"sqfeet\",\n",
    "            \"taxvaluedollarcnt\": \"tax_value\",\n",
    "            \"taxamount\": \"prop_tax\",\n",
    "            \"fips\": \"county\",\n",
    "        }\n",
    "    )\n",
    "    # Drop nulls, since it is less than 1%\n",
    "    # Before Drop NA: 2,152,863\n",
    "    # After Drop NA: 2,140,235\n",
    "    # Total Dropped: 12,628 (0.006)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use as reference for get_zillow_data\n",
    "\n",
    "```python\n",
    "def get_telco_data():\n",
    "    \"\"\"\n",
    "    get telco data will query the telco database and return all the relevant churn data within\n",
    "\n",
    "    arguments: none\n",
    "\n",
    "    return: a pandas dataframe\n",
    "    \"\"\"\n",
    "    filename = \"telco.csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM customers\n",
    "        JOIN contract_types\n",
    "        ON customers.contract_type_id = contract_types.contract_type_id\n",
    "        JOIN internet_service_types\n",
    "        ON customers.internet_service_type_id = internet_service_types.internet_service_type_id\n",
    "        JOIN payment_types\n",
    "        ON customers.payment_type_id = payment_types.payment_type_id;\"\"\"\n",
    "        connection = db_url(\"telco_churn\")\n",
    "        df = pd.read_sql(query, connection)\n",
    "        df.to_csv(filename, index=False)\n",
    "    return df\n",
    " \n",
    "def check_columns(df):\n",
    "    \"\"\"\n",
    "    This function takes in a pandas DataFrame and prints out the name of each column,\n",
    "    the number of unique values in each column, and the unique values themselves.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        The DataFrame to be checked.\n",
    "    \"\"\"\n",
    "    for column in df.columns:\n",
    "        print(f\"{column} ({df[column].nunique()})\")\n",
    "        print(f\"Unique Values: {df[column].unique()}\")\n",
    "        print(\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertting entire columns.\n",
    "\n",
    "- **Useful for converting columns, and then investigating NA values**\n",
    "\n",
    "- *May be useful to not run inplace=True or not assign it right away, to check out the funky value beforehand*\n",
    "\n",
    "```python\n",
    "pd.to_datetime()\n",
    "#  This method converts a pandas object to a datetime type. The errors parameter can be set to 'raise' to raise a ValueError if the input data is not in a recognized format, or 'coerce' to return NaT (Not a Time) for non-convertible data. \n",
    "\n",
    "pd.to_timedelta() \n",
    "# This method converts a pandas object to a timedelta type. The errors parameter can be set to 'raise' to raise a ValueError if the input data is not in a recognized format, or 'coerce' to return NaT (Not a Time) for non-convertible data.\n",
    "\n",
    "pd.to_bool()\n",
    "# This method converts a pandas object to a boolean type. The errors parameter can be set to 'raise' to raise a ValueError if the input data is not a recognized boolean value, 'coerce' to return NaN for non-convertible data, or 'ignore' to leave non-convertible data as is.\n",
    "\n",
    "pd.to_string()\n",
    "# This method converts a pandas object to a string type. This method does not have an errors parameter.\n",
    "\n",
    "pd.to_categorical()\n",
    "# This method converts a pandas object to a categorical type. The errors parameter can be set to 'raise' to raise a ValueError if the input data is not a recognized category, or 'ignore' to leave non-convertible data as is.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
